# The Birds and the Bees

#### Sam Kim, Nick Merrill, Crystal Stowell

<div class='video'>
<iframe width="672" height="378" src="http://www.youtube.com/embed/0ohAn30qqAU?&vq=hd720" frameborder="0" allowfullscreen></iframe>
</div>

## Overview

We built an infrastructure for optimization problems with the right amount of abstraction that would allow us to easily build new algorithms and problems independently.  This way, we can swap in new algorithms or new problems without starting from scratch. Our main goal was to solve constraint programming problems, particularly the Nurse Scheduling Problem. We implemented 3 metaheuristic optimization algorithms: Cuckoo Search (CS), Particle Swarm Optimization (PSO), and a hybrid of the two algorithms. These algorithms can of course also solve more basic problems.  We included four mathematical optimization test functions and three simple real-world problems in addition to the nurse scheduling problem to demonstrate the flexibility of our design as well as analyze the performance of the 3 algorithms.

The first algorithm, called the Cuckoo Search, is a metaheuristic optimization algorithm based on the behavior of the cuckoo bird **(Reference)**. Some cuckoo bird species parasitically lay their eggs in the nest of another bird species, where the likelihood of the host bird raising the bird as its own depends on how well the cuckoo mimics the egg of the host species. In this algorithm, an initial set of nests, which represent the solutions, are randomly generated.  These solutions are then updated over multiple generations.  The process of updating an individual solution is as follows: a random nest is chosen, and a new solution is generated by random-walking from this previous solution.  This new solution can then replace a different randomly chosen solution if it has a fitness value better than the original.  After this possible replacement of a solution, all of the nests are ranked by fitness and the worst fraction of the nests is replaced with random solutions.  This combination of mechanisms allows the solutions to search locally and globally at the same time for the optimal solution.

The second algorithm, called the Particle Swarm Optimization, is a relatively popular algorithm introduced in 1995, and based on the social behavior of a swarm. Each particle, which represents a solution, has a velocity that allows the particle to move around the search space. Over each generation, the particle’s position is updated using its velocity, which is biased towards the particle’s own best position and the globally best position. This mechanism of swarm intelligence is expected to move the entire swarm towards the best solutions.

The last algorithm is a hybrid of the above two algorithms that combines all the above mechanisms in each iteration. First, a new solution is generated using the random walk which may replace another solution. Next, every solution is updated using the associated velocities as described above. Finally, the worst fraction of nests is replaced with random solutions.

In addition, we built a website as the graphical user interface for our project.  Originally a terminal UI, it was agreed upon that a website was both more interactive and more descriptive.  [Here](http://optimizer.nickmerrill.me) you can select a problem, read all about it, enter your desired inputs, and choose an algorithm with which to solve.

## Planning

Three weeks ago, we set out to write an optimization algorithm.  The end goal was to be able to handle real-world problems as complex as the nurse scheduling problem and still find an optimal solution.  That goal has been met.  **WOOT!**

To see how our project played out in terms of planning, check out our documentation for [Checkpoint 1]({{STATIC_URL}}doc/checkpoint1.pdf) and [Checkpoint 2]({{STATIC_URL}}doc/checkpoint2.pdf).

In previous specifications, core features included optimization of an objective function using Cuckoo Search, providing a set of optimized solutions, and appropriate interfacing of the problem in order to change which optimization algorithm is used.

Six objective functions have been included: the Fence Problem, the Michalewicz Problem, the Box Problem, the Egg Holder Function, the Rastrigin Function, and the Nurse Scheduling Problem.  The first two problems are univariate, the next two are bivariate, and the last two are multivariate.

Cool extensions that have also been implemented include additional optimization algorithms.  In addition to the Cuckoo Search, there is also a Particle Swarm Optimization (PSO) algorithm as well as a hybrid of the two.  A friendly graphical user interface has also been added as a cool extension to allow for better user interactivity and ease of use.  This can be found at [http://optimizer.nickmerrill.me](http://optimizer.nickmerrill.me).

## Design and Implementation

Throughout the development of the project, the original design of the algorithms and solutions classes was altered to meet the needs of each class.  Specifically, changes to the abstraction of the classes were made.  However, this did not create any difficulties.

The separation and abstraction of the problems versus the algorithms made it very easy to add new problems. The abstract OptimizationProblem takes care of a lot of details related to variable constraints and interfacing with the algorithms and front-end. Implementing sub-classes only involves specifying these constraints and the fitness functions for the algorithm, and print functions for the front-end. For example, implementing the new test functions such as RastriginMinProb or EggholderFuncProb only took at most 10 minutes each to write.

Unfortunately, we did not get to implement fully everything we wanted. For example, although Cuckoo Search works well on all of the problems, PSO and the hybrid do not always reach the correct answer on problems with multivariable constraints (i.e. ax + by < c). While they do reach an answer, it is not accurate enough to say that these work without bugs.

### Analysis

**Experimental Procedures** 

Three mathematical functions commonly used in literature as benchmarks for optimization algorithms were chosen in order to analyze the performance of our three algorithms, including convergence rate and precision. We used the Rastrigin Function, the Rosenbrock Function, and the Eggholder Function. Tests were run by first normalizing the number of iterations in each algorithm such that each algorithm would take approximately the same time for a given function, and then collecting data of the best fitness over the iterations. 200 data points were collected for each run, and 50 trials for each algorithm were averaged and analyzed.

**Rastrigin Function:** This function is a fairly difficult problem due to its large search space and its large number of local minima which are regularly distributed. The plot to the right shows the function when n=2. Data was collected for n=10 over 3 seconds. As we can see in the graph below, the hybrid algorithm is very quick to converge to a good solution, but over a longer period of time the cuckoo search is able to find a better solution. The PSO performed the worst. The function is given below:

f(x)=An+ ∑_(i=1)^n▒[ x_i^2-A cos⁡(2πx_i ) where A=10,x_i∈ [-5.12,5.12]

Global minimum at x=0,f(x)=0

[Image](
